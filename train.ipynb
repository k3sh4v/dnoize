{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import Value as MPValue\n",
    "\n",
    "EPOCH_SEED = MPValue('i', 0)\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"3\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"3\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"3\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchaudio\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.all import *\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4047062",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run loss.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afe486",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch_directml\n",
    "    dml = torch_directml.device()\n",
    "    print(f\"DirectML device available: {dml} | {torch_directml.device_name(0)}\")\n",
    "    USE_DIRECTML = True\n",
    "except ImportError:\n",
    "    print(\"torch_directml not available, using CPU\")\n",
    "    USE_DIRECTML = False\n",
    "    dml = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioTensor(TensorBase):\n",
    "    \"\"\"Wrapper for audio tensors\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def load_audio(file_path, target_length=48000, role='input', rt60_range=None):\n",
    "    \"\"\"\n",
    "    Load and augment audio for a single role.\n",
    "\n",
    "    role='input':  loads noisy path, applies following strategy if rt_range is provided\n",
    "        (50%): noisy → clean          denoise only\n",
    "        (30%): reverb(noisy) → clean  joint denoise + deverb\n",
    "        (20%): reverb(clean) → clean  deverb only\n",
    "\n",
    "    role='target': whether provided file path is for noisy or clean audio\n",
    "\n",
    "    Deterministic per path+epoch — safe for any num_workers.\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    epoch_seed = EPOCH_SEED.value\n",
    "\n",
    "    if role == 'target':\n",
    "        wave_np = _load_raw_np(path)\n",
    "\n",
    "    else:\n",
    "        strategy = _get_strategy(path, epoch_seed) if rt60_range else 'denoise_only'\n",
    "\n",
    "        if strategy == 'denoise_only':\n",
    "            wave_np = _load_raw_np(path)\n",
    "\n",
    "        elif strategy == 'joint':\n",
    "            noisy_np = _load_raw_np(path)\n",
    "            try:\n",
    "                rng = _get_reverb_rng(path, epoch_seed)\n",
    "                wave_np = add_reverb(noisy_np, rt60_range=rt60_range, rng=rng)\n",
    "            except Exception:\n",
    "                wave_np = noisy_np\n",
    "\n",
    "        else:  # deverb_only\n",
    "            clean_path = Path(path.parent.as_posix().replace(\"noisy\", \"clean\"))\n",
    "            clean_np = _load_raw_np(clean_path / path.name)\n",
    "            try:\n",
    "                rng = _get_reverb_rng(path, epoch_seed)\n",
    "                wave_np = add_reverb(clean_np, rt60_range=rt60_range, rng=rng)\n",
    "            except Exception:\n",
    "                wave_np = clean_np\n",
    "\n",
    "    # Crop then pad to exact target_length\n",
    "    wave_np = wave_np[:target_length]\n",
    "    if len(wave_np) < target_length:\n",
    "        wave_np = np.pad(wave_np, (0, target_length - len(wave_np)))\n",
    "\n",
    "    return AudioTensor(torch.tensor(wave_np).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataloaders(\n",
    "    noisy_dir, clean_dir, bs=8, valid_pct=0.15, verbose=False, target_length=64000,\n",
    "    num_workers=0, device=torch.device(\"cpu\"), use_reverb=True, rt60_range=(0.2, 0.6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Create DataLoaders for VoiceBank-DEMAND dataset\n",
    "    \n",
    "    Args:\n",
    "        noisy_dir: Path to noisy audio files\n",
    "        clean_dir: Path to clean audio files\n",
    "        bs: Batch size\n",
    "        valid_pct: Validation split percentage\n",
    "        target_length: Fixed audio length in samples (64000 = 4 seconds @ 16kHz)\n",
    "        num_workers: Number of data loading workers\n",
    "    \"\"\"\n",
    "    noisy_dir = Path(noisy_dir)\n",
    "    clean_dir = Path(clean_dir)\n",
    "    \n",
    "    # Get all noisy files\n",
    "    noisy_files = sorted(list(noisy_dir.glob('*.wav')))\n",
    "    \n",
    "    # Create pairs by matching filenames\n",
    "    items = [str(noisy_file) for noisy_file in noisy_files \n",
    "             if (clean_dir / noisy_file.name).exists()]\n",
    "    \n",
    "    total   = len(items)\n",
    "    n_val   = int(total * valid_pct)\n",
    "    n_train = total - n_val\n",
    "    print(f\"Found {total} pairs  |  train={n_train}  valid={n_val}\")\n",
    "\n",
    "    if use_reverb:\n",
    "        print(f\"Strategy C enabled  |  RT60={rt60_range}\")\n",
    "        print(f\"  ~{int(n_train*0.5)} denoise only  (~50%)\")\n",
    "        print(f\"  ~{int(n_train*0.3)} joint         (~30%)\")\n",
    "        print(f\"  ~{int(n_train*0.2)} deverb only   (~20%)\")\n",
    "        print(f\"  Same distribution applied to validation\")\n",
    "    else:\n",
    "        print(f\"Augmentation disabled — straight denoising pairs\")\n",
    "\n",
    "    _rt60 = rt60_range if use_reverb else None\n",
    "    \n",
    "\n",
    "    def get_x(noisy_audio_path):\n",
    "        return load_audio(noisy_audio_path, target_length=target_length, role='input', rt60_range=_rt60)\n",
    "\n",
    "    def get_y(noisy_audio_path):\n",
    "        noisy_path = Path(noisy_audio_path)\n",
    "        clean_path = clean_dir / noisy_path.name\n",
    "        return load_audio(str(clean_path), target_length=target_length, role='target')\n",
    "    \n",
    "    # Custom type dispatch for AudioTensor\n",
    "    def AudioTensorBlock():\n",
    "        return TransformBlock(type_tfms=[], batch_tfms=[])\n",
    "    \n",
    "    dblock = DataBlock(\n",
    "        blocks=(AudioTensorBlock(), AudioTensorBlock()),\n",
    "        get_x=get_x,\n",
    "        get_y=get_y,\n",
    "        splitter=RandomSplitter(valid_pct=valid_pct, seed=42)\n",
    "    )\n",
    "    \n",
    "    dls = dblock.dataloaders(items, bs=bs, num_workers=num_workers, verbose=verbose)\n",
    "    dls = dls.to(device)\n",
    "\n",
    "    return dls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbaab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_learner(\n",
    "    train_noisy_dir=\"data/train/noisy_trainset_28spk_wav\",\n",
    "    train_clean_dir=\"data/train/clean_trainset_28spk_wav\",\n",
    "    epochs=80,\n",
    "    batch_size=8,\n",
    "    channels=96,\n",
    "    num_blocks=10,\n",
    "    num_repeats=2,\n",
    "    target_length=64000,\n",
    "    valid_pct=0.05,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    verbose=False,\n",
    "    use_reverb=True,\n",
    "    rt60_range=(0.2, 0.6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the causal noise removal model\n",
    "    \n",
    "    Args:\n",
    "        train_noisy_dir: Path to noisy training audio\n",
    "        train_clean_dir: Path to clean training audio\n",
    "        epochs: Number of training epochs\n",
    "        batch_size: Batch size\n",
    "        channels: Number of channels in model\n",
    "        num_blocks: Number of processing blocks\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Loading data from:\")\n",
    "    print(f\"Noisy: {train_noisy_dir}\")\n",
    "    print(f\"Clean: {train_clean_dir}\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    dls = generate_dataloaders(\n",
    "        train_noisy_dir, \n",
    "        train_clean_dir,\n",
    "        target_length=target_length,\n",
    "        bs=batch_size,\n",
    "        valid_pct=valid_pct,\n",
    "        device=device,\n",
    "        verbose=verbose,\n",
    "        use_reverb=use_reverb,\n",
    "        rt60_range=rt60_range\n",
    "    )\n",
    "    \n",
    "    # Show a batch to verify\n",
    "    print(\"\\nDataLoader check:\")\n",
    "    xb, yb = dls.one_batch()\n",
    "    print(f\"  Noisy batch shape: {xb.shape}\")\n",
    "    print(f\"  Clean batch shape: {yb.shape}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = CausalDNoizeConvTasNet(\n",
    "        channels=channels, num_blocks=num_blocks,\n",
    "        num_repeats=num_repeats\n",
    "    )\n",
    "    \n",
    "    # Move to DirectML device if available\n",
    "    if USE_DIRECTML:\n",
    "        model = model.to(device)\n",
    "        print(f\"\\nModel moved to DirectML device\")\n",
    "    \n",
    "    # Create learner\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        loss_func=CombinedLoss(use_spectral=True),\n",
    "        opt_func=lookahead_adamw,\n",
    "        metrics=[SISNRMetric(), NoiseReductionPct()],\n",
    "        cbs=[\n",
    "            SaveModelCallback(monitor='sisnr_db', fname='causal_dnoize_best', with_opt=True),\n",
    "            GradientClip(max_norm=1.0), GradientAccumulation(n_acc=4), SISNRDiagnostic(),\n",
    "            PeriodicPESQSTOI(every_n=10, n_batches=10)\n",
    "        ]\n",
    "    ).to_fp16(enabled=False)\n",
    "    \n",
    "    print(f\"  Batch size: {batch_size}\")\n",
    "    print(f\"  Model channels: {channels}\")\n",
    "    print(f\"  Model blocks: {num_blocks}\")\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "learn = generate_learner(\n",
    "    train_noisy_dir=\"data/train/noisy_trainset_28spk_wav\",\n",
    "    train_clean_dir=\"data/train/clean_trainset_28spk_wav\",\n",
    "    batch_size=4,\n",
    "    channels=48,\n",
    "    num_blocks=8,\n",
    "    num_repeats=2,\n",
    "    target_length=48000,\n",
    "    valid_pct=0.05,\n",
    "    device=dml,\n",
    "    use_reverb=True,\n",
    "    rt60_range=(0.2, 0.6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46473b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this on one batch to see the loss component magnitudes\n",
    "# learn.model.eval()\n",
    "# xb, yb = learn.dls.one_batch()\n",
    "# with torch.no_grad():\n",
    "#     pred = learn.model(xb)\n",
    "\n",
    "# pred_sq = pred.squeeze(1).float().cpu()\n",
    "# targ_sq = yb.squeeze(1).float().cpu()\n",
    "\n",
    "# sisnr    = si_snr_loss(pred_sq, targ_sq)\n",
    "# l1       = F.l1_loss(pred, yb)\n",
    "# pred_rms = pred.pow(2).mean(dim=-1).sqrt()\n",
    "# targ_rms = yb.pow(2).mean(dim=-1).sqrt()\n",
    "# # power_reg = F.l1_loss(pred_rms, targ_rms.detach())\n",
    "# ratio     = pred_rms / (targ_rms + 1e-8)\n",
    "# power_reg = (ratio - 1.0).abs().mean()\n",
    "\n",
    "# print(f\"sisnr:      {sisnr.item():.6f}\")\n",
    "# print(f\"l1:         {l1.item():.6f}\")\n",
    "# print(f\"power_reg:  {power_reg.item():.6f}\")\n",
    "# print(f\"pred_rms:   {pred_rms.squeeze().tolist()}\")\n",
    "# print(f\"targ_rms:   {targ_rms.squeeze().tolist()}\")\n",
    "# print(f\"ratio:      {(pred_rms / (targ_rms + 1e-8)).squeeze().tolist()}\")\n",
    "# learn.model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model.eval()\n",
    "# xb, yb = learn.dls.one_batch()\n",
    "# with torch.no_grad():\n",
    "#     pred = learn.model(xb)\n",
    "\n",
    "# pred_cpu = pred.squeeze(1).detach().float().cpu()\n",
    "# targ_cpu = yb.squeeze(1).detach().float().cpu()\n",
    "\n",
    "# pred_rms  = pred_cpu.pow(2).mean(dim=-1).sqrt()\n",
    "# targ_rms  = targ_cpu.pow(2).mean(dim=-1).sqrt()\n",
    "# ratio     = pred_rms / (targ_rms + 1e-8)\n",
    "# power_reg = (ratio - 1.0).abs().mean()\n",
    "\n",
    "# sisnr = si_snr_loss(pred_cpu, targ_cpu)\n",
    "\n",
    "# print(f\"sisnr:       {sisnr.item():.6f}\")\n",
    "# print(f\"power_reg:   {power_reg.item():.6f}\")\n",
    "# print(f\"pred_rms:    {pred_rms.tolist()}\")\n",
    "# print(f\"targ_rms:    {targ_rms.tolist()}\")\n",
    "# print(f\"ratio:       {ratio.tolist()}\")\n",
    "# print(f\"mean_ratio:  {ratio.mean().item():.4f}\")\n",
    "# print(f\"pred range:  [{pred_cpu.min().item():.4f}, {pred_cpu.max().item():.4f}]\")\n",
    "\n",
    "# learn.model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Final SI-SNR check\n",
    "# learn.model.eval()\n",
    "# xb, yb = learn.dls.one_batch()\n",
    "# with torch.no_grad():\n",
    "#     pred = learn.model(xb)\n",
    "\n",
    "# pred_cpu = pred.squeeze(1).detach().float().cpu()\n",
    "# targ_cpu = yb.squeeze(1).detach().float().cpu()\n",
    "\n",
    "# targ_zm = targ_cpu - targ_cpu.mean(dim=-1, keepdim=True)\n",
    "# pred_zm = pred_cpu - pred_cpu.mean(dim=-1, keepdim=True)\n",
    "# eps = 1e-8\n",
    "# alpha = (targ_zm * pred_zm).sum(-1, keepdim=True) / \\\n",
    "#         (targ_zm.pow(2).sum(-1, keepdim=True) + eps)\n",
    "# s = (alpha * targ_zm).pow(2).sum(-1)\n",
    "# n = (pred_zm - alpha * targ_zm).pow(2).sum(-1)\n",
    "# sisnr = 10 * torch.log10((s + eps) / (n + eps))\n",
    "\n",
    "# print(f\"SI-SNR per sample: {[round(v,2) for v in sisnr.tolist()]}\")\n",
    "# print(f\"SI-SNR mean:       {sisnr.mean().item():.4f} dB\")\n",
    "# learn.model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203681f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On resume — automatically knows how many epochs are left\n",
    "n_epochs = 200\n",
    "tracker = EpochTracker(total_epochs=n_epochs)\n",
    "epochs_remaining = 200 - tracker.epochs_done\n",
    "\n",
    "resuming_after_failure = tracker.epochs_done > 0\n",
    "\n",
    "if resuming_after_failure:\n",
    "    print(f\"Resuming from epoch {tracker.epochs_done}, {epochs_remaining} remaining\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best checkpoint saved so far on training failure\n",
    "if resuming_after_failure:\n",
    "    learn.load('causal_dnoize_best', with_opt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not resuming_after_failure:\n",
    "    suggested_lr = learn.lr_find(stop_div=False, num_it=50, suggest_funcs=(steep, valley))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f434136",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not resuming_after_failure:\n",
    "    print(suggested_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e5717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resuming_after_failure:\n",
    "    # Reduce LR proportionally to training progress\n",
    "    lr_max = tracker.saved_lr_max\n",
    "    progress  = tracker.epochs_done / tracker.total_epochs\n",
    "\n",
    "    resume_lr = lr_max * max(0.1, 1 - progress * 0.8)\n",
    "    \n",
    "    print(f\"Resume LR: {resume_lr} | Saved Max LR: {lr_max}\")\n",
    "    \n",
    "else:\n",
    "    steep  = suggested_lr.steep\n",
    "    valley = suggested_lr.valley\n",
    "    print(f\"lr_find:  steep={steep:.2e}  valley={valley:.2e}\")\n",
    "\n",
    "    # Weight steep more heavily for complex tasks —\n",
    "    # warmup (pct_start=0.05 over 200 epochs = 10 epochs) \n",
    "    # will climb from lr_max/25 to lr_max finding the sweet spot\n",
    "    w_steep, w_valley = 0.67, 0.33\n",
    "    lr_max = math.exp(\n",
    "        w_steep  * math.log(steep) +\n",
    "        w_valley * math.log(valley)\n",
    "    )\n",
    "\n",
    "    # Floor at 1e-5 — never go below this regardless of lr_find output\n",
    "    lr_max = max(lr_max, 1e-5)\n",
    "\n",
    "    print(f\"weighted geomean (steep×{w_steep} valley×{w_valley}): \"\n",
    "          f\"{lr_max:.8f}\")\n",
    "    print(f\"  warmup will climb from {lr_max/25:.2e} → {lr_max:.2e} \"\n",
    "          f\"over first 10 epochs\")\n",
    "\n",
    "    tracker.saved_lr_max = lr_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd075ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.add_cb(tracker)\n",
    "\n",
    "training_start_msg = (\n",
    "    f\"Starting training for {epochs_remaining} epochs with {\"lr_max = \"+str(lr_max) if not resuming_after_failure else \"lr = \"+str(resume_lr)} | \"\n",
    "    f\"{'fresh start' if not resuming_after_failure else 'resuming after '+str(tracker.epochs_done)+' epochs'}\"\n",
    ")\n",
    "\n",
    "print(training_start_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resuming_after_failure:\n",
    "    # no flat phase, pure cosine decay from start\n",
    "    learn.fit_flat_cos(epochs_remaining, lr=resume_lr, pct_start=0.0, wd=1e-4)\n",
    "else:\n",
    "    learn.fit_one_cycle(epochs_remaining, lr_max=lr_max, div=10, pct_start=0.05, wd=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('causal_dnoize_final', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesq_score, stoi_score = evaluate_checkpoint(\n",
    "    'models/causal_dnoize_best.pth',\n",
    "    learn.dls,\n",
    "    channels=48,\n",
    "    num_blocks=8,\n",
    "    num_repeats=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03de4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesq_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edeb7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
