{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchaudio\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.all import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4047062",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run loss.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afe486",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc4eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # ENHANCED PATCH - Shows header table + console progress updates\n",
    "# from fastprogress.fastprogress import NBMasterBar, NBProgressBar, master_bar, progress_bar\n",
    "# from IPython.display import display\n",
    "\n",
    "# print(\"Applying enhanced ProgressCallback patch...\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # PATCH 1: NBMasterBar initialization\n",
    "# # ============================================================================\n",
    "# _original_nbmasterbar_init = NBMasterBar.__init__\n",
    "\n",
    "# def _patched_nbmasterbar_init(self, gen, total=None, parent=None, display=True, leave=True, **kwargs):\n",
    "#     try:\n",
    "#         _original_nbmasterbar_init(self, gen, total, parent, display, leave, **kwargs)\n",
    "#     except Exception as e:\n",
    "#         self.gen = gen\n",
    "#         self.total = total\n",
    "#         self.parent = parent\n",
    "#         self.leave = leave\n",
    "#         self.display = display\n",
    "#         self.first_bar = None\n",
    "    \n",
    "#     if not hasattr(self, 'out'):\n",
    "#         try:\n",
    "#             from ipywidgets import Output\n",
    "#             self.out = Output()\n",
    "#             if display:\n",
    "#                 display(self.out)\n",
    "#         except:\n",
    "#             class DummyOut:\n",
    "#                 def update(self, *args, **kwargs): pass\n",
    "#             self.out = DummyOut()\n",
    "    \n",
    "#     if not hasattr(self, 'order') or not isinstance(self.order, (list, tuple)):\n",
    "#         self.order = ['main', 'text']\n",
    "    \n",
    "#     if not hasattr(self, 'inner_dict'):\n",
    "#         self.inner_dict = {}\n",
    "    \n",
    "#     if not hasattr(self, 'text_parts'):\n",
    "#         self.text_parts = []\n",
    "    \n",
    "#     if not hasattr(self, 'lines'):\n",
    "#         self.lines = []\n",
    "\n",
    "# NBMasterBar.__init__ = _patched_nbmasterbar_init\n",
    "\n",
    "# # ============================================================================\n",
    "# # PATCH 2: NBMasterBar.show()\n",
    "# # ============================================================================\n",
    "# _original_show = NBMasterBar.show\n",
    "\n",
    "# def _patched_show(self):\n",
    "#     if not hasattr(self, 'out'): return\n",
    "#     if not hasattr(self, 'inner_dict'): self.inner_dict = {}\n",
    "#     if not hasattr(self, 'text_parts'): self.text_parts = []\n",
    "#     if not hasattr(self, 'order') or not isinstance(self.order, (list, tuple)):\n",
    "#         self.order = ['main', 'text']\n",
    "#     try:\n",
    "#         from fastprogress.fastprogress import Div\n",
    "#         if self.text_parts:\n",
    "#             self.inner_dict['text'] = Div(*self.text_parts)\n",
    "#         children = []\n",
    "#         for n in self.order:\n",
    "#             item = self.inner_dict.get(n)\n",
    "#             if item is not None:\n",
    "#                 child = getattr(item, 'progress', None) or item\n",
    "#                 children.append(child)\n",
    "#         if children and hasattr(self.out, 'update'):\n",
    "#             self.out.update(Div(*children))\n",
    "#     except: pass\n",
    "\n",
    "# NBMasterBar.show = _patched_show\n",
    "\n",
    "# # ============================================================================\n",
    "# # PATCH 3: NBMasterBar.write() - Enhanced with console output\n",
    "# # ============================================================================\n",
    "# _original_write = NBMasterBar.write\n",
    "\n",
    "# def _patched_write(self, line, table=False):\n",
    "#     if not hasattr(self, 'lines'): self.lines = []\n",
    "#     if not hasattr(self, 'text_parts'): self.text_parts = []\n",
    "    \n",
    "#     # ALWAYS print to console for visibility\n",
    "#     if table and isinstance(line, list):\n",
    "#         # Skip printing the header (first line)\n",
    "#         if len(self.lines) > 0:  # This is data, not header\n",
    "#             print(' | '.join(f'{x:>12}' if isinstance(x, (int, float)) else f'{x:>12}' for x in line))\n",
    "    \n",
    "#     try:\n",
    "#         from fastprogress.fastprogress import text2html_table, P\n",
    "#         if table:\n",
    "#             self.lines.append(line)\n",
    "#             self.text_parts = [text2html_table(self.lines)]\n",
    "#         else:\n",
    "#             self.text_parts.append(P(line))\n",
    "#         self.show()\n",
    "#     except:\n",
    "#         # Fallback console output\n",
    "#         if isinstance(line, (list, tuple)):\n",
    "#             print(' | '.join(str(x) for x in line))\n",
    "#         else:\n",
    "#             print(line)\n",
    "\n",
    "# NBMasterBar.write = _patched_write\n",
    "\n",
    "# # ============================================================================\n",
    "# # PATCH 4: NBMasterBar.update() - Add console progress\n",
    "# # ============================================================================\n",
    "# _original_update = NBMasterBar.update\n",
    "\n",
    "# def _patched_update(self, val=None):\n",
    "#     try:\n",
    "#         _original_update(self, val)\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     # Print epoch progress to console\n",
    "#     if val is not None and hasattr(self, 'total'):\n",
    "#         if self.total:\n",
    "#             pct = (val + 1) / self.total * 100\n",
    "#             print(f\"\\rEpoch {val + 1}/{self.total} ({pct:.0f}%)\", end='', flush=True)\n",
    "\n",
    "# NBMasterBar.update = _patched_update\n",
    "\n",
    "# # ============================================================================\n",
    "# # PATCH 5: NBProgressBar for batch progress (optional)\n",
    "# # ============================================================================\n",
    "# _original_nbprogress_update = NBProgressBar.update\n",
    "\n",
    "# def _patched_nbprogress_update(self, val=None):\n",
    "#     try:\n",
    "#         _original_nbprogress_update(self, val)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# NBProgressBar.update = _patched_nbprogress_update\n",
    "\n",
    "# print(\"âœ“ Enhanced ProgressCallback patched\")\n",
    "# print(\"  - Table header will display\")\n",
    "# print(\"  - Metrics will print to console after each epoch\")\n",
    "# print(\"  - Epoch progress will show inline\")\n",
    "# print(\"\\nYou can now train:\")\n",
    "# print(\"  learn.fit_one_cycle(80, lr_max=3e-4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch_directml\n",
    "    dml = torch_directml.device()\n",
    "    print(f\"DirectML device available: {dml} | {torch_directml.device_name(0)}\")\n",
    "    USE_DIRECTML = True\n",
    "except ImportError:\n",
    "    print(\"torch_directml not available, using CPU\")\n",
    "    USE_DIRECTML = False\n",
    "    dml = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioTensor(TensorBase):\n",
    "    \"\"\"Wrapper for audio tensors\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def load_audio(path_str, target_length=64000):\n",
    "    \"\"\"Load and preprocess audio file\"\"\"\n",
    "    path_str = Path(path_str)\n",
    "    wave, sr = torchaudio.load(str(path_str))\n",
    "    \n",
    "    # Convert to mono\n",
    "    if wave.shape[0] > 1:\n",
    "        wave = wave.mean(0, keepdim=True)\n",
    "    \n",
    "    # Resample if needed\n",
    "    if sr != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "        wave = resampler(wave)\n",
    "    \n",
    "    # Pad or crop to target length\n",
    "    current_length = wave.shape[1]\n",
    "    if current_length < target_length:\n",
    "        padding = target_length - current_length\n",
    "        wave = F.pad(wave, (0, padding))\n",
    "    else:\n",
    "        wave = wave[:, :target_length]\n",
    "    \n",
    "    return AudioTensor(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataloaders(noisy_dir, clean_dir, bs=8, valid_pct=0.15, verbose=False,\n",
    "                              target_length=64000, num_workers=0, device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Create DataLoaders for VoiceBank-DEMAND dataset\n",
    "    \n",
    "    Args:\n",
    "        noisy_dir: Path to noisy audio files\n",
    "        clean_dir: Path to clean audio files\n",
    "        bs: Batch size\n",
    "        valid_pct: Validation split percentage\n",
    "        target_length: Fixed audio length in samples (64000 = 4 seconds @ 16kHz)\n",
    "        num_workers: Number of data loading workers\n",
    "    \"\"\"\n",
    "    noisy_dir = Path(noisy_dir)\n",
    "    clean_dir = Path(clean_dir)\n",
    "    \n",
    "    # Get all noisy files\n",
    "    noisy_files = sorted(list(noisy_dir.glob('*.wav')))\n",
    "    \n",
    "    # Create pairs by matching filenames\n",
    "    items = [str(noisy_file) for noisy_file in noisy_files \n",
    "             if (clean_dir / noisy_file.name).exists()]\n",
    "    \n",
    "    print(f\"Found {len(items)} audio pairs\")\n",
    "    \n",
    "    def get_x(noisy_audio_path):\n",
    "        return load_audio(noisy_audio_path, target_length)\n",
    "    \n",
    "    def get_y(noisy_audio_path):\n",
    "        noisy_path = Path(noisy_audio_path)\n",
    "        clean_path = clean_dir / noisy_path.name\n",
    "        return load_audio(str(clean_path), target_length)\n",
    "    \n",
    "    # Custom type dispatch for AudioTensor\n",
    "    def AudioTensorBlock():\n",
    "        return TransformBlock(type_tfms=[], batch_tfms=[])\n",
    "    \n",
    "    dblock = DataBlock(\n",
    "        blocks=(AudioTensorBlock(), AudioTensorBlock()),\n",
    "        get_x=get_x,\n",
    "        get_y=get_y,\n",
    "        splitter=RandomSplitter(valid_pct=valid_pct, seed=42)\n",
    "    )\n",
    "    \n",
    "    dls = dblock.dataloaders(items, bs=bs, num_workers=num_workers, verbose=verbose)\n",
    "    dls = dls.to(dml)\n",
    "\n",
    "    return dls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbaab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_learner(\n",
    "    train_noisy_dir=\"data/train/noisy_trainset_28spk_wav\",\n",
    "    train_clean_dir=\"data/train/clean_trainset_28spk_wav\",\n",
    "    epochs=80,\n",
    "    lr=3e-4,\n",
    "    batch_size=8,\n",
    "    channels=96,\n",
    "    num_blocks=4,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the causal noise removal model\n",
    "    \n",
    "    Args:\n",
    "        train_noisy_dir: Path to noisy training audio\n",
    "        train_clean_dir: Path to clean training audio\n",
    "        epochs: Number of training epochs\n",
    "        lr: Learning rate\n",
    "        batch_size: Batch size\n",
    "        channels: Number of channels in model\n",
    "        num_blocks: Number of processing blocks\n",
    "        use_56spk: Use 56 speaker dataset instead of 28\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Loading data from:\")\n",
    "    print(f\"Noisy: {train_noisy_dir}\")\n",
    "    print(f\"Clean: {train_clean_dir}\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    dls = generate_dataloaders(\n",
    "        train_noisy_dir, \n",
    "        train_clean_dir,\n",
    "        target_length=80000,\n",
    "        bs=batch_size,\n",
    "        valid_pct=0.1,\n",
    "        device=device,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Show a batch to verify\n",
    "    print(\"\\nDataLoader check:\")\n",
    "    xb, yb = dls.one_batch()\n",
    "    print(f\"  Noisy batch shape: {xb.shape}\")\n",
    "    print(f\"  Clean batch shape: {yb.shape}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = CausalDNoizeConvTasNet(channels=channels, num_blocks=num_blocks)\n",
    "    \n",
    "    # Move to DirectML device if available\n",
    "    if USE_DIRECTML:\n",
    "        model = model.to(dml)\n",
    "        print(f\"\\nModel moved to DirectML device\")\n",
    "    \n",
    "    # Create learner\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        loss_func=CombinedLoss(),\n",
    "        opt_func=Adam,\n",
    "        metrics=[pesq_metric, stoi_metric, DenoisingAccuracy()],\n",
    "        cbs=[\n",
    "            SaveModelCallback(\n",
    "                monitor='accuracy_%',\n",
    "                fname='causal_dnoize_best'\n",
    "            )\n",
    "        ]\n",
    "    ).to_fp16(enabled=False)\n",
    "    \n",
    "    # Override device if using DirectML\n",
    "    if USE_DIRECTML:\n",
    "        learn.dls.device = device\n",
    "        learn.model = learn.model.to(device)\n",
    "    \n",
    "    print(f\"  Batch size: {batch_size}\")\n",
    "    print(f\"  Model channels: {channels}\")\n",
    "    print(f\"  Model blocks: {num_blocks}\")\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = generate_learner(\n",
    "    train_noisy_dir=\"data/train/noisy_trainset_28spk_wav\",\n",
    "    train_clean_dir=\"data/train/clean_trainset_28spk_wav\",\n",
    "    batch_size=4,\n",
    "    channels=128,\n",
    "    num_blocks=6,\n",
    "    device=dml\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd075ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_epochs = 150\n",
    "lr = 0.000575\n",
    "best_pesq = 0\n",
    "\n",
    "print(\"Starting training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(n_epochs, lr_max=lr, div=25, pct_start=0.3, wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('causal_dnoize_final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
